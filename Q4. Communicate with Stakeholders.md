# Analysis

Q.4 Construct an email or slack message that is understandable to a product or business leader who isn’t familiar with your day to day work. This part of the exercise should show off how you communicate and reason about data with others. Commit your answers to the git repository along with the rest of your exercise.

Slack message:

Hi John,\
Hope you're having a great day. I was working around three datasets provided to me by the Sr. leadershop to work on some analysis. The first datasets is  `receipt` dataset which contains data about receipts, the time when the receipt was scanned, the points awarded to the user for the specific receipt, reject/approved status of the receipt, etc. The other dataset I studied was the `brands` dataset. It contains the data about the barcode of a specific item the brand associated with it the category of th item, name of the brands, etc. The last dataset I worked on was the `users` dataset which contained data about the users like the state they belong to, the user created date, last activity, etc.

I've worked around the data and build the best possible relational database for the data set which will help us find out answers such as 'What are the top 5 brands by receipts scanned for most recent month?', 'When considering total number of items purchased from receipts with 'rewardsReceiptStatus’ of ‘Accepted’ or ‘Rejected’, which is greater?', etc. Also I found a few data quality issues in the dataset such as duplication of the data in the users dataset and missing data points in brands dataset and the receipt dataset. I have provided the detailed issue and possible solution in the files attached.

TL;DR I worked around three datasets receipt, users and brands to build a relational database to answer a few important questions. Later on I found out a few data quality issues which are crucial and has to be improved. I've attached a file for your reference. 

Please let me know if you have any questions on the above.

### 1. What questions do you have about the data?
A:	The different date fields captured in the receipts dataset such as `dateScanned`, `finishDate`, `createDate`,etc. Why do we have different types of dates and how are each of them significant to the business?\
\
2. How can we connect the receipt data with the revenue data?\
How does receipts generate revenue for the company\
\
3. How my analysis (from task2) drive business decisions? Which specific decisions can be driven out of that analysis?

### 2.	How did you discover the data quality issues?
A: 1. During the exploratory data analysis stage I found out that the users data has key value pair of `'_id'` that stores the user id for each user. I found out duplicate dictiories for mulitple `userId` in the user dataset. Duplication of data is clearly observed. Given that any Engineer will use the `userID` as the primary key for the users table, it should be a unique non redundant value and in the users dataset.\
\
2. Querying the brands table I found out that many items in the brands table have null values in the `category` column. Category is a curcial data point that helps us understand the demand, popularity of the products amoung customer in a given market and hence it is extremely imporant to have `category` associated to each item.\
\
3. Digging into the `rewardsReceiptItemList` dictionary in the `receipts` dataset. I found out there were multiple items missing key value pair for `barcode` and `brandCode`. If we are not able to retrieve `brandCode` or `barcode` for items on the list, it doesn't actually show us the whole picture of purhcase history and the customer purchase behavior. So every item on the receipt should have `barcode` or `brandCode` associated to understand purchase trend for different categories and brands.

### 3. What do you need to know to resolve the data quality issues?
A: 1. Understanding the process of the data collection and the reason behind why we have a lot of missing data points can help us find solution on how to make the process better in order to collect more data points for receipts and brands dataset.\
\
2. Gather a team of engineers to perform QA in a regular cadence of the database schema to make sure we are keeping the data accurate and clean.

### 4. What other information would you need to help you optimize the data assets you're trying to create?
A: Having information about customer's app activity such as the browsing data of the customer in the app, using that we can create customer affinity bubbles and personalize the app based on customer interest. For example, showing offers on products that the customers are interested in or sending emails for he associated products can enhance customer engagement on the platform and lead to more sales of the products i.e. receipts uploads.

### 5. What performance and scaling concerns do you anticipate in production and how do you plan to address them?
A: 1. When we think about scaling and performance the first thing that comes to my mind is storing good quality data and one of the qualities of a good quality data is duplication free data. If we don't remove duplicates from the users dataset, It might lead us to wrong direction. Removing duplicates increases one more step to achieve data integrity of the database, so it'd be ideal that the data first stored in the logs doesn't contain duplicated rows, duplication also run into performance and cost poroblems.\
\
2. Missing data points such as brandcode and brandcode in receiptItemList will give us incomplete analysis on sales of the products. It can lead us to wrong decisions for the product and the business. So it is crucial that when we scale the data we need to have all the data points collected for every tables.\
\
To solve the above issues we need to work better on the data collection and interpretation of data via OCR.
When we're scaling our database, it is important to not allow for any redundancies. Redundancies occur when there are several entries in database that contains similar information. 
